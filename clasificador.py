# -*- coding: utf-8 -*-
# ===============================================================
# üåæ PREDWEEM ‚Äî Zero: Entrena y predice curvas acumuladas (0..1)
#  - Fuente: meteorolog√≠a (tmin, tmax, prec) + curvas hist√≥ricas
#  - Rango temporal fijo: JD 1..274 (1-ene ‚Üí 1-oct)
#  - Modelo: MLPRegressor multisalida (128 neuronas, 1500 iter)
#  - Tabs: ‚ë† Entrenamiento ‚ë° Predicci√≥n ‚ë¢ Evaluaci√≥n hist√≥rica
# ===============================================================

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import io, re, joblib
from io import BytesIO
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error

st.set_page_config(page_title="PREDWEEM Zero ‚Äî Acumulada 0..1", layout="wide")
st.title("üåæ PREDWEEM Zero ‚Äî Entrenamiento y Predicci√≥n (acumulada 0..1 ¬∑ JD 1..274)")

JD_MAX = 274
XRANGE = (1, JD_MAX)

# ---------------------------------------------------------------
# Utilidades
# ---------------------------------------------------------------
def standardize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).lower().strip() for c in df.columns]
    ren = {
        "temperatura minima": "tmin", "t_min": "tmin", "t min": "tmin", "m√≠nima": "tmin",
        "tminima": "tmin", "min": "tmin",
        "temperatura maxima": "tmax", "t_max": "tmax", "t max": "tmax", "m√°xima": "tmax",
        "tmaxima": "tmax", "max": "tmax",
        "precipitacion": "prec", "precip": "prec", "pp": "prec", "lluvia": "prec", "rain": "prec",
        "dia juliano": "jd", "d√≠a juliano": "jd", "julian_days": "jd", "dia": "jd", "d√≠a": "jd",
        "fecha": "fecha", "date": "fecha"
    }
    for k, v in ren.items():
        if k in df.columns:
            df = df.rename(columns={k: v})
    if "fecha" in df.columns:
        df["fecha"] = pd.to_datetime(df["fecha"], errors="coerce", dayfirst=True)
    for c in ["tmin", "tmax", "prec", "jd"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def ensure_jd_1_to_274(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "jd" not in df.columns:
        if "fecha" in df.columns and df["fecha"].notna().any():
            # Reinicia JD desde el 1-ene detectado
            y0 = int(df["fecha"].dt.year.mode().iloc[0])
            df = df[(df["fecha"] >= f"{y0}-01-01") & (df["fecha"] <= f"{y0}-10-01")].copy().sort_values("fecha")
            df["jd"] = df["fecha"].dt.dayofyear - pd.Timestamp(f"{y0}-01-01").dayofyear + 1
        else:
            df["jd"] = np.arange(1, len(df) + 1)
    df = (df.set_index("jd")
            .reindex(range(1, JD_MAX + 1))
            .interpolate()
            .ffill().bfill()
            .reset_index())
    return df

def curva_desde_xlsx_anual(file) -> np.ndarray:
    """
    Lee un XLSX con dos columnas [d√≠a, valor] (diaria o semanal).
    Devuelve curva acumulada normalizada 0..1 en JD 1..274.
    - Si paso=1 ‚Üí agrega por d√≠a y acumula.
    - Si paso~7 ‚Üí considera ‚Äúvalor‚Äù semanal en el d√≠a indicado.
    """
    df = pd.read_excel(file, header=None)
    # Tolerante: si tiene encabezado, reintenta sin header=None
    if df.shape[1] < 2:
        df = pd.read_excel(file)
    df = df.copy()
    # Detectar columnas num√©ricas
    col0 = pd.to_numeric(df.iloc[:, 0], errors="coerce")
    col1 = pd.to_numeric(df.iloc[:, 1], errors="coerce")
    # Si col0 no es num√©rica, puede ser fecha tipo "22-mar"
    if col0.isna().mean() > 0.5:
        try:
            fch = pd.to_datetime(df.iloc[:, 0], errors="coerce", dayfirst=True)
            jd = fch.dt.dayofyear
            val = pd.to_numeric(df.iloc[:, 1], errors="coerce").fillna(0.0)
        except Exception:
            # fallback: todo cero
            daily = np.zeros(365, float)
            curva = np.cumsum(daily); 
            return (curva/curva.max())[:JD_MAX] if curva.max()>0 else np.zeros(JD_MAX)
    else:
        jd = col0.astype("Int64")
        val = col1.fillna(0.0)

    # Detecta paso t√≠pico (1 vs 7)
    jd_clean = jd.dropna().astype(int).sort_values().unique()
    if len(jd_clean) > 1:
        paso = int(np.median(np.diff(jd_clean)))
    else:
        paso = 7

    daily = np.zeros(365, dtype=float)
    if paso == 1:
        # ‚Äúval‚Äù es relativo diario ‚Üí suma diaria
        for d, v in zip(jd, val):
            if pd.notna(d) and 1 <= int(d) <= 365:
                daily[int(d) - 1] += float(v)
    else:
        # ‚Äúval‚Äù es relativo semanal ‚Üí ubica valor en el d√≠a y suaviza con ventana 7
        for d, v in zip(jd, val):
            if pd.notna(d) and 1 <= int(d) <= 365:
                daily[int(d) - 1] += float(v)
        # distribuir a la semana por media m√≥vil para evitar escalones
        kernel = np.ones(7) / 7
        daily = np.convolve(daily, kernel, mode="same")

    acum = np.cumsum(daily)
    if np.nanmax(acum) == 0:
        return np.zeros(JD_MAX, dtype=float)
    curva = acum / np.nanmax(acum)
    return curva[:JD_MAX]

def build_xy(meteo_dict: dict, curvas_dict: dict):
    common = sorted(set(meteo_dict.keys()) & set(curvas_dict.keys()))
    X, Y, years = [], [], []
    for y in common:
        dfm = meteo_dict[y]
        x = np.concatenate([dfm["tmin"].to_numpy(), dfm["tmax"].to_numpy(), dfm["prec"].to_numpy()])
        X.append(x)
        Y.append(curvas_dict[y])
        years.append(y)
    return np.array(X), np.array(Y), np.array(years)

def emerg_rel_7d_from_acum(y_acum: np.ndarray) -> np.ndarray:
    inc = np.diff(np.insert(y_acum, 0, 0.0))
    rel7 = np.convolve(inc, np.ones(7) / 7, mode="same")
    return rel7

# ---------------------------------------------------------------
# UI ‚Äî Tabs
# ---------------------------------------------------------------
tabs = st.tabs(["üß™ Entrenamiento (hist√≥rico)", "üîÆ Predicci√≥n nueva", "üìä Evaluaci√≥n hist√≥rica"])

# ===============================================================
# TAB 1 ‚Äî ENTRENAMIENTO
# ===============================================================
with tabs[0]:
    st.subheader("üß™ Entrenamiento base desde meteorolog√≠a + curvas acumuladas")

    meteo_book = st.file_uploader("üìò Meteorolog√≠a multianual (una hoja por a√±o)", type=["xlsx", "xls"])
    st.caption("La planilla debe contener por hoja un a√±o, con columnas: fecha o jd, tmin, tmax, prec.")

    st.markdown("**üì• Curvas hist√≥ricas (acumuladas 0..1):** sub√≠ uno o varios XLSX anuales.")
    curvas_files = st.file_uploader("Cargar XLSX por a√±o (2008, 2009, ..., 2025)", type=["xlsx", "xls"], accept_multiple_files=True)

    seed = st.number_input("Semilla aleatoria", 0, 99999, 42)
    neurons = st.slider("Neuronas (capa oculta)", 16, 256, 128, step=16)
    max_iter = st.slider("Iteraciones (max_iter)", 300, 5000, 1500, step=100)

    btn_train = st.button("üöÄ Entrenar modelo")

    if btn_train:
        if not meteo_book or not curvas_files:
            st.error("Carg√° la meteorolog√≠a y al menos una curva hist√≥rica.")
            st.stop()

        # 1) Meteorolog√≠a por a√±o
        sheets = pd.read_excel(meteo_book, sheet_name=None)
        meteo_dict = {}
        for name, df in sheets.items():
            df = standardize_cols(df)
            df = ensure_jd_1_to_274(df)
            try:
                year = int(re.findall(r"\d{4}", str(name))[0])
            except Exception:
                # intenta deducir por la columna fecha
                if "fecha" in df.columns and df["fecha"].notna().any():
                    year = int(df["fecha"].dt.year.mode().iloc[0])
                else:
                    year = None
            if year and all(c in df.columns for c in ["tmin", "tmax", "prec"]):
                meteo_dict[year] = df[["jd", "tmin", "tmax", "prec"]].copy()

        if not meteo_dict:
            st.error("No se pudo construir meteorolog√≠a por a√±o con columnas tmin, tmax, prec.")
            st.stop()
        st.success(f"‚úÖ Meteorolog√≠a cargada para {len(meteo_dict)} a√±os.")

        # 2) Curvas acumuladas por a√±o (desde XLSX anuales)
        curvas_dict = {}
        for f in curvas_files:
            try:
                y4 = re.findall(r"(\d{4})", f.name)
                year = int(y4[0]) if y4 else None
                curva = curva_desde_xlsx_anual(f)
                if year is not None and np.nanmax(curva) > 0:
                    curvas_dict[year] = curva
            except Exception:
                pass

        if not curvas_dict:
            st.error("No se detectaron curvas v√°lidas en los XLSX anuales.")
            st.stop()
        st.success(f"‚úÖ Curvas acumuladas cargadas para {len(curvas_dict)} a√±os.")

        # 3) Construir X, Y y entrenar
        X, Y, years = build_xy(meteo_dict, curvas_dict)
        if len(years) < 3:
            st.warning("Muy pocos a√±os en com√∫n entre meteo y curvas. Se recomienda ‚â• 5.")
        # Normalizar Y para forzar final en 1
        for i in range(Y.shape[0]):
            if Y[i][-1] != 1.0 and np.nanmax(Y[i]) > 0:
                Y[i] = Y[i] / Y[i][-1]

        # LOO para m√©tricas por a√±o
        kf = KFold(n_splits=len(years))
        metrics = []
        xsc, ysc = StandardScaler(), StandardScaler()
        for train, test in kf.split(X):
            Xtr, Xte = X[train], X[test]
            Ytr, Yte = Y[train], Y[test]
            Xtr_s, Xte_s = xsc.fit_transform(Xtr), xsc.transform(Xte)
            Ytr_s = ysc.fit_transform(Ytr)
            mlp = MLPRegressor(hidden_layer_sizes=(neurons,), max_iter=max_iter, random_state=seed)
            mlp.fit(Xtr_s, Ytr_s)
            Yhat = ysc.inverse_transform(mlp.predict(Xte_s))
            rmse = float(np.sqrt(mean_squared_error(Yte[0], Yhat[0])))
            mae = float(mean_absolute_error(Yte[0], Yhat[0]))
            metrics.append((int(years[test][0]), rmse, mae))

        dfm = pd.DataFrame(metrics, columns=["A√±o", "RMSE", "MAE"]).sort_values("A√±o")
        st.markdown("### üìä M√©tricas Leave-One-Year-Out")
        st.dataframe(dfm, use_container_width=True)

        # Entrenamiento final en todo el set
        xsc.fit(X); ysc.fit(Y)
        mlp_final = MLPRegressor(hidden_layer_sizes=(neurons,), max_iter=max_iter, random_state=seed)
        mlp_final.fit(xsc.transform(X), ysc.transform(Y))

        # Guardar en sesi√≥n y ofrecer descarga
        st.session_state["predweem_bundle"] = {"xsc": xsc, "ysc": ysc, "mlp": mlp_final}
        st.success("‚úÖ Modelo entrenado y guardado en sesi√≥n.")

        buf = io.BytesIO()
        joblib.dump(st.session_state["predweem_bundle"], buf)
        st.download_button(
            "üíæ Descargar modelo entrenado (.joblib)",
            data=buf.getvalue(),
            file_name="predweem_bundle.joblib",
            mime="application/octet-stream"
        )

# ===============================================================
# TAB 2 ‚Äî PREDICCI√ìN
# ===============================================================
with tabs[1]:
    st.subheader("üîÆ Predicci√≥n de curva acumulada (0..1) a partir de meteorolog√≠a nueva")

    modelo_up = st.file_uploader("üì¶ Cargar modelo (.joblib)", type=["joblib"])
    meteo_pred = st.file_uploader("üìò Meteorolog√≠a nueva (XLSX)", type=["xlsx", "xls"], key="pred")

    show_hist = st.checkbox("Mostrar promedio hist√≥rico (si entrenaste en esta sesi√≥n)", value=True)

    if st.button("Predecir curva"):
        if not (modelo_up and meteo_pred):
            st.error("Carg√° el modelo y la meteorolog√≠a.")
            st.stop()
        try:
            bundle = joblib.load(modelo_up)
            xsc, ysc, mlp = bundle["xsc"], bundle["ysc"], bundle["mlp"]

            df = pd.read_excel(meteo_pred)
            df = standardize_cols(df)
            df = ensure_jd_1_to_274(df)

            faltan = [c for c in ["tmin", "tmax", "prec"] if c not in df.columns]
            if faltan:
                st.error(f"Faltan columnas meteorol√≥gicas: {faltan}")
                st.stop()

            xnew = np.concatenate([df["tmin"], df["tmax"], df["prec"]]).reshape(1, -1)
            yhat = ysc.inverse_transform(mlp.predict(xsc.transform(xnew)))[0]
            yhat = np.maximum.accumulate(yhat)
            yhat = yhat / (yhat[-1] if yhat[-1] != 0 else 1.0)
            yhat = np.clip(yhat, 0, 1)

            dias = np.arange(1, JD_MAX + 1)
            df_pred = pd.DataFrame({"D√≠a": dias, "Emergencia predicha": yhat})

            layers = []
            if show_hist and "predweem_bundle" in st.session_state:
                st.caption("Mostrando promedio hist√≥rico estimado a partir de las curvas usadas en esta sesi√≥n (si las hubiere).")
                # Si en esta sesi√≥n hubo curvas en TAB 1, podemos reconstruir promedio aprox
                # (guard√° en tu flujo real el promedio si quer√©s precisi√≥n).
                # Ac√°, solo mostramos la predicci√≥n (capa principal).
            line_pred = alt.Chart(df_pred).mark_line(color="#e67300", strokeWidth=2.5).encode(
                x=alt.X("D√≠a:Q", title=f"D√≠a juliano (1‚Äì{JD_MAX})", scale=alt.Scale(domain=list(XRANGE))),
                y=alt.Y("Emergencia predicha:Q", title="Emergencia acumulada (0‚Äì1)", scale=alt.Scale(domain=[0, 1]))
            )
            layers += [line_pred]

            rel = emerg_rel_7d_from_acum(yhat)
            df_rel = pd.DataFrame({"D√≠a": dias, "Emergencia relativa 7d": rel})
            area_rel = alt.Chart(df_rel).mark_area(opacity=0.25).encode(
                x="D√≠a:Q",
                y=alt.Y("Emergencia relativa 7d:Q", axis=alt.Axis(title="Emergencia relativa 7d"))
            )
            line_rel = alt.Chart(df_rel).mark_line(strokeDash=[5,3]).encode(
                x="D√≠a:Q",
                y="Emergencia relativa 7d:Q"
            )
            layers += [area_rel, line_rel]

            chart = alt.layer(*layers).resolve_scale(y='independent').properties(height=460, title="Curva predicha + relativa 7d")
            st.altair_chart(chart, use_container_width=True)

            out = pd.DataFrame({"D√≠a": dias, "Emergencia_predicha": yhat, "Emergencia_relativa_7d": rel})
            st.download_button(
                "‚¨áÔ∏è Descargar curva (CSV)",
                out.to_csv(index=False).encode("utf-8"),
                file_name="curva_predicha.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"Error en la predicci√≥n: {e}")

# ===============================================================
# TAB 3 ‚Äî EVALUACI√ìN HIST√ìRICA (opcional r√°pido)
# ===============================================================
with tabs[2]:
    st.subheader("üìä Evaluaci√≥n r√°pida con curvas hist√≥ricas (si quer√©s re-chequear)")

    st.markdown("Sub√≠ las **mismas curvas anuales** que usaste para entrenar y evaluamos el ajuste Leave-One-Year-Out.")
    curvas_eval = st.file_uploader("Curvas hist√≥ricas (XLSX por a√±o)", type=["xlsx", "xls"], accept_multiple_files=True, key="eval_curvas")
    meteo_book_eval = st.file_uploader("Meteorolog√≠a multianual (XLSX)", type=["xlsx", "xls"], key="eval_meteo")
    modelo_eval = st.file_uploader("Modelo entrenado (.joblib)", type=["joblib"], key="eval_model")
    btn_eval = st.button("üîé Evaluar")

    if btn_eval:
        if not (curvas_eval and meteo_book_eval and modelo_eval):
            st.error("Faltan archivos para la evaluaci√≥n.")
            st.stop()
        try:
            # meteorolog√≠a
            sheets = pd.read_excel(meteo_book_eval, sheet_name=None)
            meteo_dict = {}
            for name, df in sheets.items():
                df = standardize_cols(df)
                df = ensure_jd_1_to_274(df)
                try:
                    year = int(re.findall(r"\d{4}", str(name))[0])
                except:
                    if "fecha" in df.columns and df["fecha"].notna().any():
                        year = int(df["fecha"].dt.year.mode().iloc[0])
                    else:
                        year = None
                if year and all(c in df.columns for c in ["tmin", "tmax", "prec"]):
                    meteo_dict[year] = df[["jd", "tmin", "tmax", "prec"]].copy()

            curvas_dict = {}
            for f in curvas_eval:
                y4 = re.findall(r"(\d{4})", f.name)
                year = int(y4[0]) if y4 else None
                curva = curva_desde_xlsx_anual(f)
                if year is not None and np.nanmax(curva) > 0:
                    curvas_dict[year] = curva

            X, Y, years = build_xy(meteo_dict, curvas_dict)
            for i in range(Y.shape[0]):
                if Y[i][-1] != 1.0 and np.nanmax(Y[i]) > 0:
                    Y[i] = Y[i] / Y[i][-1]

            bundle = joblib.load(modelo_eval)
            xsc, ysc, mlp = bundle["xsc"], bundle["ysc"], bundle["mlp"]

            # Evaluaci√≥n directa (no reentrena)
            preds, metrics = [], []
            for i, y in enumerate(years):
                xnew = X[i].reshape(1, -1)
                yhat = ysc.inverse_transform(mlp.predict(xsc.transform(xnew)))[0]
                yhat = np.maximum.accumulate(yhat)
                yhat = yhat / (yhat[-1] if yhat[-1] != 0 else 1.0)
                yhat = np.clip(yhat, 0, 1)
                rmse = float(np.sqrt(mean_squared_error(Y[i], yhat)))
                mae = float(mean_absolute_error(Y[i], yhat))
                metrics.append((int(y), rmse, mae))
                preds.append((y, yhat))

            dfm = pd.DataFrame(metrics, columns=["A√±o", "RMSE", "MAE"]).sort_values("A√±o")
            st.dataframe(dfm, use_container_width=True)

            # Gr√°fico por a√±o (selector)
            opt_year = st.selectbox("Ver detalle del a√±o:", options=[int(y) for y in years])
            y_true = Y[list(years).index(opt_year)]
            y_hat = dict(preds)[opt_year]
            dias = np.arange(1, JD_MAX + 1)
            df_plot = pd.DataFrame({
                "D√≠a": dias,
                "Emergencia real": y_true,
                "Emergencia predicha": y_hat
            }).melt("D√≠a", var_name="Serie", value_name="Valor")
            chart = alt.Chart(df_plot).mark_line().encode(
                x=alt.X("D√≠a:Q", scale=alt.Scale(domain=list(XRANGE))),
                y=alt.Y("Valor:Q", title="Emergencia acumulada (0‚Äì1)", scale=alt.Scale(domain=[0, 1])),
                color="Serie:N"
            ).properties(height=420, title=f"Detalle {opt_year}")
            st.altair_chart(chart, use_container_width=True)

        except Exception as e:
            st.error(f"Error en la evaluaci√≥n: {e}")

