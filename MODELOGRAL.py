# -*- coding: utf-8 -*-
# üìà Emergencia acumulada hist√≥rica ‚Äî an√°lisis comparativo por d√≠a juliano
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import re
from pathlib import Path
from io import StringIO

# ============ CONFIG ============ #
st.set_page_config(page_title="Emergencia Acumulada Hist√≥rica", layout="wide")
st.title("An√°lisis hist√≥rico de emergencia acumulada")

st.markdown(
    """
- Carga autom√°tica de archivos anuales (Excel) en el directorio actual.  
- Exclusiones: **2010** y **2015**.  
- La curva de cada a√±o se **normaliza** a 1 (100%) en el d√≠a 365.  
- Eleg√≠ el **d√≠a juliano** y un **umbral** (por defecto 50%) para ver estad√≠sticas.  
- Se muestra el **promedio**, bandas **P10‚ÄìP90** e **IQR (P25‚ÄìP75)**.
"""
)

# ============ UTILIDADES ============ #
def _parse_year_from_name(name: str) -> str:
    m = re.match(r"^(\d+)", name)
    return m.group(1) if m else name

def _is_excluded(yr: str) -> bool:
    # excluir 2010 y 2015
    try:
        y = int(yr)
        return y in (2010, 2015)
    except:
        return False

@st.cache_data
def cargar_curvas_desde_excels(directorio: str = "."):
    """
    Busca *.xlsx en 'directorio', arma curvas normalizadas (365 d√≠as),
    y devuelve (dict_a√±o->np.array(365,), listado_a√±os_ordenado).
    """
    p = Path(directorio)
    archivos = sorted([f for f in p.glob("*.xlsx")])

    curvas = {}
    for f in archivos:
        anno = _parse_year_from_name(f.stem)
        if _is_excluded(anno):
            continue
        try:
            # Asumimos dos columnas: d√≠a juliano y valor diario
            df = pd.read_excel(f, header=None)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è No se pudo leer {f.name}: {e}")
            continue

        if df.empty or df.shape[1] < 2:
            st.warning(f"‚ö†Ô∏è Formato inesperado en {f.name}; se requieren 2 columnas (d√≠a, valor).")
            continue

        # Coerci√≥n segura
        dias = pd.to_numeric(df.iloc[:, 0], errors="coerce").to_numpy()
        vals = pd.to_numeric(df.iloc[:, 1], errors="coerce").to_numpy()
        mask = ~np.isnan(dias) & ~np.isnan(vals)
        dias, vals = dias[mask], vals[mask]

        # Vector diario (365)
        v = np.zeros(365, dtype=float)
        for d, val in zip(dias, vals):
            try:
                idx = int(d) - 1
                if 0 <= idx < 365:
                    v[idx] += float(val)  # si hay duplicados en un d√≠a, se suma
            except:
                pass

        curva_acum = np.cumsum(v)
        fin = curva_acum[-1]
        if fin > 0:
            curva_norm = curva_acum / fin
        else:
            # si no hubo datos > 0, dejamos todo en 0
            curva_norm = curva_acum

        curvas[anno] = curva_norm

    # ordenar por a√±o num√©rico si es posible
    def _key(a):
        try:
            return int(a)
        except:
            return a

    anios = sorted(curvas.keys(), key=_key)
    return curvas, anios

# ============ LECTURA ============ #
curvas_dict, anios_disponibles = cargar_curvas_desde_excels(".")
if not anios_disponibles:
    st.error("No se encontraron archivos .xlsx v√°lidos en el directorio actual (excluyendo 2010 y 2015).")
    st.stop()

# ============ CONTROLES ============ #
colA, colB, colC = st.columns([1.2, 1, 1])
with colA:
    anios_sel = st.multiselect(
        "A√±os a incluir",
        options=anios_disponibles,
        default=anios_disponibles,
        key="ms_anios",
        help="Pod√©s filtrar a√±os para el an√°lisis y las curvas."
    )
with colB:
    dia_sel = st.slider("D√≠a juliano", min_value=1, max_value=365, value=180, key="k_dia")
with colC:
    umbral = st.slider("Umbral (fracci√≥n)", min_value=0.05, max_value=0.95, value=0.50, step=0.05, key="k_umbral")

if not anios_sel:
    st.warning("Seleccion√° al menos un a√±o.")
    st.stop()

# ============ ARMADO MATRIZ (n_a√±os x 365) ============ #
mat = np.vstack([curvas_dict[a] for a in anios_sel])  # shape: (N, 365)
N = mat.shape[0]

# Estad√≠sticas por d√≠a seleccionado
idx = dia_sel - 1
valores_dia = mat[:, idx]
media = float(np.mean(valores_dia))
desv  = float(np.std(valores_dia))
mediana = float(np.median(valores_dia))
p10 = float(np.percentile(valores_dia, 10))
p25 = float(np.percentile(valores_dia, 25))
p75 = float(np.percentile(valores_dia, 75))
p90 = float(np.percentile(valores_dia, 90))
prob_sup = float(np.mean(valores_dia > umbral))

st.markdown(
    f"""
**Resultados para el d√≠a {dia_sel}:**  
- Promedio: **{media*100:.1f}%** (¬± {desv*100:.1f}%)  
- Mediana: **{mediana*100:.1f}%**  
- Percentiles: **P10={p10*100:.1f}%**, **P25={p25*100:.1f}%**, **P75={p75*100:.1f}%**, **P90={p90*100:.1f}%**  
- Probabilidad de superar **{umbral*100:.0f}%**: **{prob_sup*100:.1f}%**  
"""
)

# ============ DATAFRAME para Altair ============ #
dias = np.arange(1, 366)
df_lineas = []
for a in anios_sel:
    curva = curvas_dict[a]
    df_lineas.append(
        pd.DataFrame({"D√≠a": dias, "Fracci√≥n": curva, "Serie": a})
    )
df_lineas = pd.concat(df_lineas, ignore_index=True)

# Curva promedio y bandas
curva_mean = mat.mean(axis=0)
curva_p10  = np.percentile(mat, 10, axis=0)
curva_p25  = np.percentile(mat, 25, axis=0)
curva_p75  = np.percentile(mat, 75, axis=0)
curva_p90  = np.percentile(mat, 90, axis=0)

df_stats = pd.DataFrame({
    "D√≠a": dias,
    "mean": curva_mean,
    "p10":  curva_p10,
    "p25":  curva_p25,
    "p75":  curva_p75,
    "p90":  curva_p90
})

# ============ GR√ÅFICO PRINCIPAL ============ #
base = alt.Chart().encode(
    x=alt.X("D√≠a:Q", title="D√≠a del a√±o")
)

band_p10_90 = base.mark_area(opacity=0.15).encode(
    y=alt.Y("p10:Q", title="Fracci√≥n acumulada"),
    y2="p90:Q",
).transform_lookup(
    lookup="D√≠a",
    from_=alt.LookupData(df_stats, "D√≠a", ["p10", "p90"])
)

band_iqr = base.mark_area(opacity=0.25).encode(
    y="p25:Q",
    y2="p75:Q",
).transform_lookup(
    lookup="D√≠a",
    from_=alt.LookupData(df_stats, "D√≠a", ["p25", "p75"])
)

line_mean = base.mark_line(size=3).encode(
    y="mean:Q",
    color=alt.value("#000")  # negro para destacar el promedio
).transform_lookup(
    lookup="D√≠a",
    from_=alt.LookupData(df_stats, "D√≠a", ["mean"])
)

line_years = alt.Chart(df_lineas).mark_line(opacity=0.6).encode(
    x="D√≠a:Q",
    y=alt.Y("Fracci√≥n:Q", title="Fracci√≥n acumulada (0‚Äì1)", scale=alt.Scale(domain=[0, 1])),
    color=alt.Color("Serie:N", title="A√±o")
)

rule_day = alt.Chart(pd.DataFrame({"D√≠a": [dia_sel]})).mark_rule(color="red", strokeDash=[4,4]).encode(x="D√≠a:Q")

chart = (band_p10_90 + band_iqr + line_years + line_mean + rule_day).properties(height=420)
st.altair_chart(chart, use_container_width=True)

# ============ HISTOGRAMA (distribuci√≥n del d√≠a seleccionado) ============ #
st.subheader("Distribuci√≥n en el d√≠a seleccionado")
df_hist = pd.DataFrame({"Fracci√≥n": valores_dia, "A√±o": anios_sel})
hist = alt.Chart(df_hist).mark_bar().encode(
    x=alt.X("Fracci√≥n:Q", bin=alt.Bin(maxbins=20), title="Fracci√≥n acumulada en el d√≠a seleccionado"),
    y=alt.Y("count():Q", title="Frecuencia"),
    tooltip=[alt.Tooltip("count():Q", title="Frecuencia")]
).properties(height=220)
rule_thr = alt.Chart(pd.DataFrame({"Fracci√≥n": [umbral]})).mark_rule(color="red", strokeDash=[4,4]).encode(x="Fracci√≥n:Q")
st.altair_chart(hist + rule_thr, use_container_width=True)

# ============ TABLA Y DESCARGA ============ #
st.subheader("Valores por a√±o en el d√≠a seleccionado")
df_resumen = pd.DataFrame({
    "A√±o": anios_sel,
    "Fracci√≥n_d√≠a": valores_dia,
    "Porcentaje_d√≠a": valores_dia * 100
}).sort_values("A√±o", key=lambda s: s.map(lambda x: int(x) if str(x).isdigit() else x))

st.dataframe(
    df_resumen.style.format({"Fracci√≥n_d√≠a": "{:.3f}", "Porcentaje_d√≠a": "{:.1f}"}),
    use_container_width=True
)

# CSV de descarga (resumen del d√≠a)
csv_buf = StringIO()
df_resumen.to_csv(csv_buf, index=False)
st.download_button(
    "‚¨áÔ∏è Descargar resumen (CSV)",
    data=csv_buf.getvalue(),
    file_name=f"resumen_dia_{dia_sel}.csv",
    mime="text/csv",
    key="dl_resumen"
)

# CSV con todas las curvas seleccionadas (365 filas por a√±o)
st.subheader("Descarga de todas las curvas seleccionadas (normalizadas)")
df_todas = []
for a in anios_sel:
    df_todas.append(pd.DataFrame({"A√±o": a, "D√≠a": dias, "Fracci√≥n": curvas_dict[a]}))
df_todas = pd.concat(df_todas, ignore_index=True)

csv_buf2 = StringIO()
df_todas.to_csv(csv_buf2, index=False)
st.download_button(
    "‚¨áÔ∏è Descargar curvas (CSV)",
    data=csv_buf2.getvalue(),
    file_name="curvas_normalizadas.csv",
    mime="text/csv",
    key="dl_curvas"
)

st.caption("Bandas sombreadas: IQR (P25‚ÄìP75, m√°s oscuro) y P10‚ÄìP90 (m√°s claro). La l√≠nea negra es el promedio.")

